Document Title,Abstract,Publication_month,Publication_Year,PDF Link
Real-time depth map processor for offset aperture based single camera system,"This paper presents a Offset Aperture (OA) based single camera system and proposes a optimized vision processor, a new hardware architecture for fast, low-energy, and low-complexity depth extraction. The proposed design was fabricated in 110nm CMOS image sensor technology and supports 32-level depth resolution on 1920×1080 full HD image with 30fps, consuming 280.53mW from 1.5V supply and a mere 2.8% of bad classification. The low-complexity algorithms are employed to eliminate the DRAM access, thereby the proposed OA architecture can be directly embedded with the CMOS image sensor and commercial image processing chip.",2,2018,https://ieeexplore.ieee.org/abstract/document/8297326
Flicker-Free Method for Video Captured at 120-Hz Frame Frequency by Interlaced Scanning and Electrical Shutter,We propose a flicker-free method for video captured at a 120-Hz frame frequency and a 100-Hz illumination intensity variation frequency by using interlaced scanning and an electrical shutter to broadcast video during the 2020 Olympic Games in Tokyo. We found from the results of image simulation that the human eye cannot identify the decrease in vertical resolution of images with interlaced scanning when they are displayed at a 120-Hz frame frequency. We found that flicker in video captured with the flicker-free method was suppressed to less than one-twentieth of the flicker with 120-Hz progressive scanning as a result of implementation. The sensitivity of the prototype camera head with the flicker-free method also became 1.2 times higher than that with 120-Hz progressive scanning. The 120-Hz flicker-free method could be adopted in a fieldprogrammable gate array of the prototype camera head that has already been developed with a 120-Hz frame frequency.,1,2018,https://www.jstage.jst.go.jp/article/mta/6/1/6_124/_article/-char/ja/
DMDs for multi-object near-infrared spectrographs in astronomy,"The Digital Micromirror Device (DMD), typically used in projection screen technology, has utility in instrumentation for astronomy as a digitally programmable slit in a spectrograph. When placed at an imaging focal plane the device can be used to selectively direct light from astronomical targets into the optical path of a spectrograph, while at the same time directing the remaining light into an imaging camera, which can be used for slit alignment, science imaging, or both. To date the use of DMDs in astronomy has been limited, especially for instruments that operate in the near infrared (1 - 2.5 μm). This limitation is due in part to a host of technical challenges with respect to DMDs that, to date, have not been thoroughly explored. Those challenges include operation at cryogenic temperature, control electronics that facilitate DMD use at these temperatures, window coatings properly coated for the near infrared bandpass, and scattered light. This paper discusses these technical challenges and presents progress towards understanding and mitigating them.",2,2018,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10546/2291184/DMDs-for-multi-object-near-infrared-spectrographs-in-astronomy/10.1117/12.2291184.short
Implementation of Real-Time Histogram-based Contrast Enhancement Algorithm on FPGA with the Prevention of Memory Collision,"Contrast enhancement is essential for image sensor processing. This paper addresses the memory collision problem in contrast enhancement and reduces the delay of the output of the built system by exploiting the temporal locality of the frame from video camera. The proposed work reduces the output delay of the contrast enhancement algorithm from one frame (more than 2,703,600 cycles) to 519 cycles where the total hardware utilization of Xilinx Zynq ZC706 FPGA evaluation board is less than 0.4%, which is the considerably low hardware cost.",6,2018,http://www.dbpia.co.kr/Journal/ArticleDetail/NODE07515699
Time-Shared Execution of Realtime Computer Vision Pipelines by Dynamic Partial Reconfiguration,"This paper presents an FPGA runtime framework that demonstrates the feasibility of using dynamic partial reconfiguration (DPR) for time-sharing an FPGA by multiple realtime computer vision pipelines. The presented time-sharing runtime framework manages an FPGA fabric that can be round-robin time-shared by different pipelines at the time scale of individual frames. In this new use-case, the challenge is to achieve useful performance despite high reconfiguration time. The paper describes the basic runtime support as well as four optimizations necessary to achieve realtime performance given the limitations of DPR on today's FPGAs. The paper provides a characterization of a working runtime framework prototype on a Xilinx ZC706 development board. The paper also reports the performance of realtime computer vision pipelines when time-shared.",5,2018,https://arxiv.org/abs/1805.10431
CAMERA-TO-TOUCHSCREEN DESIGN,"The present paper describes an FPGA design of a camera-to-touchscreen demonstrator that has been prepared using Xilinx Vivado 2015.2 and SDK 2015.2 tools. The demonstrator consists of MicroZed 7020 Carrier Board, Avnet 7-inch Zed Touch Display and Avnet Toshiba Industrial 1080P60 Camera Module. The camera transmits a full HD video signal at 60 frames per seconds to MicroZed 7020 board, which processes it and sends to the LCD display with active area of 800×480 pixels. As the display has smaller resolution, only a fragment of the whole video frame can be seen at once on the display, whereas the full image is stored in the memory. By touching the screen one can travel along the stored video frame and look through the whole image. The design can be used, for example, as a car rear view mirror monitor benefiting from touchscreen technologies. ",8,2018,https://cyberleninka.ru/article/n/camera-to-touchscreen-design
Hardware Implementation of a Smart Camera with Keypoint Detection and Description,"Feature detection and description constitute important steps of many computer vision applications such as object detection and panorama stitching. Since those steps are computationally heavy, they might occupy significant portion of the full operation. Although fast feature detection algorithms and resource-efficient binary description methods have been proposed and implemented, resource limited embedded devices and distributed camera systems still require more effective solutions. In this paper, we propose a novel smart camera architecture which finds the FAST keypoints and computes their FREAK descriptions by processing pixel stream. Thus, this smart camera system provides useful metadata associated with the pixel stream at the same time with no latency. Moreover, performance of this hardware reaches very high frame rates with power and area efficiency. With this approach, this costly operation is locally solved in the smart camera node, and this leads to meet timing and power constraints of the large camera networks.",5,2018,https://ieeexplore.ieee.org/abstract/document/8351538/
An Investigation towards Effectiveness in Image Enhancement Process in MPSoC,"Image enhancement has a primitive role in the vision-based applications. It involves the processing of the input image by boosting its visualization for various applications. The primary objective is to filter the unwanted noises, clutters, sharpening or blur. The characteristics such as resolution and contrast are constructively altered to obtain an outcome of an enhanced image in the bio-medical field. The paper highlights the different techniques proposed for the digital enhancement of images. After surveying these methods that utilize Multiprocessor System-on-Chip (MPSoC), it is concluded that these methodologies have little accuracy and hence none of them are efficiently capable of enhancing the digital biomedical images. ",4,2018,https://search.proquest.com/openview/74bb2e8cd1e760c91964b3fb6b0a46b8/1?pq-origsite=gscholar&cbl=1686344
Rapid Design of Real-Time Image Fusion on FPGA using HLS and Other Techniques,"During the process of implementing a parameterized hardware IP generator for an image fusion algorithm, we had a chance to test various tools and techniques such as HLS, pipelining, and PCIe logic/software porting, which we developed in a previous design project. Image fusion combines two or more images through a color transformation process. Depending on the application, different fps and/or resolution may be needed. Yet the specifics of the image-processing algorithm may frequently change causing redesign. If the target platform is FPGA, usually rapid yet optimized hardware implementation is required. All these requirements cannot be met only by HLS. Clever approaches in terms of architectural techniques such as unorthodox ways of pipelining, RTL coding, and creative ways of porting interface logic/software allowed us to meet the requirements outlined above. With all these in our arsenal, we were able to get 3 versions of the algorithm (with different fps and/or resolution) running on Cyclone IV and Arria 10 FPGAs in a fairly short amount of time. This paper explains the image fusion algorithm, our hardware architecture as well as our specific flow for rapid implementation of it.",10,2018,https://ieeexplore.ieee.org/abstract/document/8612836
NIPM-sWMF: Towards Efficient FPGA Design for High-Definition Large-Disparity Stereo Matching,"Large disparity stereo matching is critical to the application of stereo vision system especially for outdoor scenes. Nevertheless, how to efficiently design high accuracy large-disparity stereo matching on FPGA is still a grand challenge. The computational complexity of previously proposed stereo matching is inevitably proportional to disparity range, hence their hardware designs become very inefficient when the disparity range is large. Motivated by the original PatchMatch and weighted median filtering algorithms, this paper proposes a NIPM-sWMF algorithm to significantly reduce the computational complexity of stereo matching and make it independent of disparity range. Moreover, we also propose a fully pipelined architecture design on FPGA that employs several hardware techniques to efficiently implement the proposed NIPM-sWMF. The disparity quality of the proposed NIPM-sWMF algorithm is evaluated on both KITTI2015 and Middlebury V3 stereo datasets, and the proposed architecture design is implemented and synthesized on Xilinx FPGA. Evaluation results demonstrate that, the proposed NIPM-sWMF design on FPGA reaches the real-time performance of 1920×1080@60Hz at the disparity range of 128, and can achieve almost the same disparity estimation accuracy, 4.5× processing throughput, while reducing the hardware cost of LUT, Register, DSP and BRAM by 40%, 47%, 100% and 68% respectively, compared with the reference stereo matching design. Therefore, the proposed NIPM-sWMF design is an efficient way to address the challenge of large-disparity stereo matching.",5,2018,https://ieeexplore.ieee.org/abstract/document/8355677
An Investigation towards Effectiveness in Image Enhancement Process in MPSoC.,"Image enhancement has a primitive role in the vision-based applications. It involves the processing of the input image by boosting its visualization for various applications. The primary objective is to filter the unwanted noises, clutters, sharpening or blur. The characteristics such as resolution and contrast are constructively altered to obtain an outcome of an enhanced image in the bio-medical field. The paper highlights the different techniques proposed for the digital enhancement of images. After surveying these methods that utilize Multiprocessor System-on-Chip (MPSoC), it is concluded that these methodologies have little accuracy and hence none of them are efficiently capable of enhancing the digital biomedical images.",4,2018,https://www.iaescore.com/journals/index.php/IJECE/article/view/8907
The Tomo-e Gozen wide field CMOS camera for the Kiso Schmidt telescope,"The Tomo-e Gozen is a wide-field high-speed camera for the Kiso 1.0-m Schmidt telescope, with a field-of-view of 20.7-deg2 covered by 84 chips of 2k x 1k CMOS image sensors with 19-μm pixels. It is capable to take consecutive images at 2-fps in full-frame read with an absolute time accuracy of 0.2 millisecond. The sensors are operated without mechanical coolers owing to a low dark current at room temperature. A low read noise of 2-e- achieves higher sensitivity than that with a CCD sensor in short exposures. Big data of 30-TBytes per night produced in the 2-fps observations is processed in real-time to quickly detect transient events and issue alerts for follow-ups.",7,2018,https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10702/2310049/The-Tomo-e-Gozen-wide-field-CMOS-camera-for-the/10.1117/12.2310049.short
Implementing a Stereo Image Correction Method for 3D Surgery Microscopes,"Recently 3D scenes are used in various industrial fields such as medical applications, computer games, surface examinations, biology and others. 3D optical microscopes can show extremely precise details in 3D. To reconstruct the 3D images of an optical microscope, two cameras are mounted on the optical microscope. Incoming images through an object lens of an optical microscope are projected on sensors of mounted cameras by using refraction mirrors. Two cameras capture the left and right images to reconstruct the final 3D images. In this paper, we correct the 3D reconstruction errors with the SURF algorithm. We also design a hardware system to correct wrong mirror positions using servo motors. In addition, we propose the surgical system with HMD and wireless communications. This system would be helpful for doctors due to make doctors comfortable and it can be used to educate surgery procedures.",1,2018,https://www.riverpublishers.com/journal_read_html_article.php?j=JSN/2016/1/9
Biomedical Equipment Development: from Custom Circuits to Software and Building Blocks,"Eleven biomedical equipment prototypes developed by Núcleo de Ingeniería Biomédica (NIB) from Universidad de la República (Uruguay) in 1987 to 2001 are reviewed. Based on interdisciplinary work of Medical School and Engineering Faculty members, the new instruments and software tools satisfy clinical and research needs in Biomedicine, and they are available for technological transfer to industry. Mean development time was 2543 man-hours (std dev=993) which accounted for 89,5% (std dev=10,5%) of total costs @ 20 USD/hour. An updated design of the projects is proposed, using present day elements, devices and development tools, yielding cost reductions in 2017 of up to 68% in materials costs, after a mean of 25 years. All prototypes developed were and some still are in clinical use, while only one of them evolved into a commercial product, confirming the one-to-ten ratio of successful investment in risk.",8,2018,http://revistasabi.fi.mdp.edu.ar/index.php/revista/article/view/141
The FPGA Based System for High Dynamic Range Automotive Camera (FPGA),"A system for capturing and processing a digital imaging system with a Sony IMX390 two-dimensional sensor supports high-dynamic imaging. To develop the system, the ZC706 development board was used for the Zynq-7000 SoC family of circuits. The Zynq-7000 consists of FPGAs and ARM processors integrated on the same chip. In the FPGA section, the whole image processing pipeline and the picture display system were implemented on the monitor. The processor system performs a demonstration application that sequentially includes individual piping modules for the purpose of displaying the influence of a particular module. The error detection process is explained in the system operation. The simple modification of the system is shown due to the flexibility provided by the FPGA circuit.",7,2018,https://bib.irb.hr/prikazi-rad?rad=958356
System and method for display auto-correction impedance mismatch control,"A method and information handling system including a display device connector for connecting to a digital display device, a controller executing instructions of an impedance mismatch control system for determining impedance differences along an operative connection from the display device connector to the digital display device, where the controller receives a display device connector impedance measurement and a second impedance measurement from a point further along the operative connection between the display device connector and the digital display device, and the controller executes the impedance mismatch control system to determine an impedance mismatch exists from the impedance difference between the display device connector and the point further along the operative connection between the display device connector and the digital display device.",5,2018,https://patents.google.com/patent/US20180151151A1/en
System Design and Implementation with Improved FCWS Detection Speed,"Recently, the Advanced Driver-Assistance Systems (ADAS) system has been installed to assist the safe operation of the vehicle. The LDWS and Forward Collision Warning System (FCWS) are the core of the Among these, FCWS has been evaluated as a key assistive technology to prevent vehicle collision. Therefore, many algorithms have been developed and tested for detection and actual detection algorithms have been commercialized. It has the best effect by combining hardware and BSP driver (Board Support Package) and algorithm. In this paper,We propose the design of a system that optimizes the FCWS by analyzing the hardware structure of the embedded system,",1,2018,http://ki-it.com/_PR/view/?aidx=12752&bidx=968#!po=4.16667
Apparatuses and methods for measuring transmit signal power leaking into adjacent radio channels,"The present disclosure relates to an apparatus for a wireless communication system. The apparatus comprises transmitter circuitry configured to generate a transmit signal on an assigned radio channel, and transmitter feedback receiver circuitry coupled to the transmitter circuitry and configured to estimate an amount of transmit signal power that leaks into adjacent radio channels based on a fed back version of the transmit signal.",6,2018,https://patents.google.com/patent/US20180175949A1/en
System for development and emulation of embedded systems,"A computer based electronic device emulation and development system includes examining a target platform program and determining a first memory location utilized by the target platform program, and providing a first software object to a host program containing a function that allows access to the first memory location.",12,2018,https://patents.google.com/patent/US20180357150A1/en
Sistema de captura y procesado de video para aviónica,"This Final Project is part of the OIT project (On-Board Information Terminal) that has been developed in the avionics department of Sainsel Sistemas Navales, a company specializing in military applications. The OIT is a multifunction presentation system designed for the use on board military aircraft. The system offers a human-machine interface that allows the flight crew to interact with the central computer on which the refueling and mission planning applications are executed. It also allows to request and visualize the image captured by the video cameras of the EVS system (Enhanced Vision System).The system consists of a modular processor called PU (Process Unit) and a touch screen device called DU (Display Unit). The PU is installed in the avionics bay and communicates via Ethernet with the DU device, which is housed in the cockpit of the aircraft. The PU receives the remote desktop from the central computer and sends it to the DU device. This desktop contains the user interface of the application software with which the flight crew interacts through the touch screen of the DU. In addition to the presentation of the remote desktop, the DU offers a contextual menu that allows the user to select one of the available cameras of the EVS system. After the selection, the PU receives a command through the Ethernet interface which is replicated through a serial port connected to an external device called VMU (Video Multiplexer Unit) that is part of the EVS system. This equipment is responsible for switching between the different video inputs and offers a single stream in HD-SDI format. For the reception of the video, the PU has the CAPT-SDI system, which consists of a hardware dedicated to the capture, compression and transmission of video with low latency. The target of this Final Degree Project has been the design and development of the CAPT-SDI system, whose implementation has been analyzed and finally carried out through a hardware architecture that combines an FPGA (Field Programmable Gate Array) Arria V GX device for the capture and processing tasks and an iMX6Q device for compression and transmission over IP (Internet Protocol). The project is focused on the design of the digital system built in the FPGA, which incorporates instances of complex IP (Intellectual Property) dedicated to the reception and processing of real-time video, memory interfaces, own logic and a instance of embedded processor Nios II, which executes the system control algorithm.",7,2018,http://oa.upm.es/53214/
High-fidelity 3d reconstruction using facial features lookup and skeletal poses in voxel models,"Techniques for high-fidelity three-dimensional (3D) reconstruction of a dynamic scene as a set of voxels are provided. One technique includes: receiving, by a processor, image data from each of two or more spatially-separated sensors observing the scene from a corresponding two or more vantage points; generating, by the processor, the set of voxels from the image data on a frame-by-frame basis; reconstructing, by the processor, surfaces from the set of voxels to generate low-fidelity mesh data; identifying, by the processor, performers in the scene from the image data; obtaining, by the processor, high-fidelity mesh data corresponding to the identified performers; and merging, by the processor, the low-fidelity mesh data with the high-fidelity mesh data to generate high-fidelity 3D output. The identifying of the performers includes: segmenting, by the processor, the image data into objects; and classifying, by the processor, those of the objects representing the performers.",8,2018,https://patents.google.com/patent/US20180240244A1/en
Utility Based Scheduling for Multi-UAV Search Systems in Disaster-Hit Areas,"Using micro or small unmanned aerial vehicles (UAVs) is a promising solution for search and rescue of missing persons who have disappeared during emergencies, such as natural disasters. In actual situations, the processing time of image data should be considered due to the wide variety of computing resources provided by UAVs. In addition, network connectivity and transmission speed could be unstable since communication infrastructure may have been damaged in disaster-hit areas. Thus, both the processing time of the acquired data and the data transfer time are critical in search and rescue missions. Unlike the solutions proposed in the past, we propose a scheduling method of multi-UAV search systems that takes into account both the processing time of image data and the data transfer time. We present a utility-based problem formulation that ensures continuously updating information while obtaining as many pieces of information as possible for a certain period. The simulation results indicate that the proposed scheduling method maximizes user utility and performs better than a conventional scheduling method in terms of user-centric evaluation metrics.",2,2019,https://ieeexplore.ieee.org/abstract/document/8648443
Methods and systems for controlling angular intensity patterns in a real space 3d image,"A system for displaying one or more images in three dimensions. The system has a three dimensional illumination volume containing a gas that emits one or more types of visible light when at certain multi-photon excited states. The system includes lasers (e.g. lasers with beams outside of the visible wavelengths) that can be directed to intersect in the illumination volume to excite particles of the gas to a multi-photon excited state to emit visible light. Scanning the beam intersection (or multiple beam intersections) through the illumination volume generates three dimensional images. In some embodiments, the system includes lasers that can be directed to intersect in the illumination volume to excite particles to an intermediate state that absorbs at least a portion of the emitted radiation from particles excited to a multi-photon excited state.",9,2018,https://patents.google.com/patent/US20180267326A1/en
Early sub-pixel rendering,A display system includes a display device and a graphics processing unit (GPU) coupled via at least one physical layer. The display device includes a pixel array having a non-red-green-blue (non-RGB) pixel format. The GPU is configured to render an image in the non-RGB pixel format and provide the rendered image for transmission to the pixel array via the at least one physical layer.,5,2018,https://patents.google.com/patent/US20180137598A1/en
Low resolution rgb rendering for efficient transmission,"A display device includes a pixel array and a display controller. The pixel array has a non-red-green-blue (non-RGB) pixel format that includes at least first, second, and third color components, and wherein sub-pixels of the first color component are present at a first resolution and sub-pixels of each of the second and third color components are present at a second resolution lower than the first resolution. The display controller is configured to receive a first image in a an RGB pixel format in which sub-pixels of the first color component, sub-pixels of the second color component, and sub-pixels of the third color component each are present in the first image at the second resolution. The display controller further is configured to scale sub-pixels of the first color component in the first image from the second resolution to the first resolution to generate a second image having the non-RGB format.",5,2018,https://patents.google.com/patent/US20180137602A1/en
Dual-path foveated graphics pipeline,"A foveated display system includes a rendering device including at least one graphics processing unit (GPU) to render a foveal region and a peripheral region of a first image, wherein the foveal region has a higher resolution than the peripheral region. The system further includes a display device coupled to the rendering device via at least one physical layer. The display device includes a pixel array and a display controller coupled to the pixel array. The display controller includes a scaling component to upscale the first peripheral region to generate a scaled first peripheral region and a blending component to blend the foveal region with the scaled first peripheral region to generate a second image.",5,2018,https://patents.google.com/patent/US20180136720A1/en
"Automated discovery and notification mechanism for obsolete display software, and/or sub-optimal display settings","Techniques for managing a display device coupled to a media processing (MP) device are described. An MP logic/module implemented by the MP device can retrieve data from a display device and identify information characterizing the display device in a database based on the retrieved data. The MP logic/module can compare the retrieved data with the identified information and determine, based on the comparison, that software installed on the display device is obsolete, or that one or more settings of the display device has a first configuration. The MP logic/module can also generate a notification based on the determination, which can be displayed on the display device. The MP logic/module can trigger performance of an action based on the determination. Actions can include downloading an updated software to memory, installing the updated software, or changing the one or more settings from the first configuration to a second, more optimal configuration.",3,2018,https://patents.google.com/patent/US20180088933A1/en
Method of controlling display and electronic device for providing the same,"An electronic device, method and computer readable medium are disclosed herein. The electronic device may comprise memory, such as the computer readable medium. The memory may include program instructions executable to implement the method, including identifying, by a controller, load information of the electronic device including execution of an application, detecting screen display information based on the identified load information by the controller, and controlling a display of the electronic device to display an execution screen of the application on the based on the detected screen display information.",1,2019,https://patents.google.com/patent/US10181305B2/en
Virtual reality system including social graph,The disclosure includes a system and method for receiving viewing data that describes a location of a first user's gaze while viewing virtual reality content. The method also determining an object of interest in the virtual reality content based on the location of the first user's gaze. The method also includes generating a social network that includes the first user as a member of the social network. The method also includes performing an action in the social network related to the object of interest.,3,2018,https://patents.google.com/patent/US20180059783A1/en
Systems and methods for configuring a hub-centric virtual/augmented reality environment,"In certain embodiments, a sensing and tracking system detects objects, such as user input devices or peripherals, and user interactions with them. A representation of the objects and user interactions are then injected into the virtual reality environment. The representation can be an actual reality, augmented reality, virtual representation or any combination. For example, an actual keyboard can be injected, but with the keys pressed being enlarged and lighted.",6,2018,https://patents.google.com/patent/US20180173323A1/en
Systems and methods for a peripheral-centric augmented/virtual reality environment,"In certain embodiments, a sensing and tracking system detects objects, such as user input devices or peripherals, and user interactions with them. A representation of the objects and user interactions are then injected into the virtual reality environment. The representation can be an actual reality, augmented reality, virtual representation or any combination. For example, an actual keyboard can be injected, but with the keys pressed being enlarged and lighted.",6,2018,https://patents.google.com/patent/US20180181194A1/en
Systems and methods for operating an input device in an augmented/virtual reality environment,"In some embodiments, a system comprising one or more processors configured to track a location of an input device within a physical environment via a three-dimensional (3D) tracking system, and modify a tracking parameter of the 3D tracking system while tracking the location of the input device based on the determined location of the input device within the physical environment. The input device may be coupled to a virtual reality display system and tracking the location of the location of the input device can be used for interacting with the virtual reality display system.",6,2018,https://patents.google.com/patent/US20180181199A1/en
