"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication_Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,"Reference Count","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"A 95pJ/label Wide-Range Depth-Estimation Processor for Full-HD Light-Field Applications on FPGA","L. Chen; Y. Lu; Y. Hiao; B. Yang; W. Chen; C. Huang","Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan","2018 IEEE Asian Solid-State Circuits Conference (A-SSCC)","","2018","","","261","262","High-resolution and wide-range depth maps are the key to enable novel light-field applications, such as digital refocusing, view synthesis, and 3D reconstruction. In this paper, we present an energy-efficient depth-estimation processor on FPGA to meet this purpose. There are two major contributions. First, image-guided depth inference and upsampling is adopted and implemented to provide accurate depth maps while lowering the working frequency from 215MHz to 54MHz. Second, octave search range sampling is proposed to efficiently allocate depth labels for wide-depth-range scenes to save computation and maintain accuracy. Finally, the implementation result on Xilinx ZC706 shows ASIC-comparable energy efficiency-95pJ/label-for Full-HD five-view light fields at 30fps.","","978-1-5386-6413-1978-1-5386-6414","10.1109/ASSCC.2018.8579289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8579289","light field;depth estimation;FPGA;Full HD","Field programmable gate arrays;Random access memory;Energy efficiency;Estimation;Image resolution;Hardware","application specific integrated circuits;field programmable gate arrays;image sampling;inference mechanisms","octave search range sampling;FPGA;digital refocusing;energy-efficient depth-estimation processor;image-guided depth inference;Xilinx ZC706;ASIC;full-HD light-field applications;wide-range depth-estimation processor;3D reconstruction;depth label allocation;frequency 54.0 MHz to 215.0 MHz","","","4","","","","","IEEE","IEEE Conferences"
"An efficient FPGA implementation of HEVC intra prediction","H. Azgin; A. C. Mert; E. Kalali; I. Hamzaoglu","Faculty of Engineering and Natural Sciences, Sabanci University, 34956 Tuzla, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, 34956 Tuzla, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, 34956 Tuzla, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, 34956 Tuzla, Istanbul, Turkey","2018 IEEE International Conference on Consumer Electronics (ICCE)","","2018","","","1","5","Intra prediction algorithm used in High Efficiency Video Coding (HEVC) standard has very high computational complexity. In this paper, an efficient FPGA implementation of HEVC intra prediction is proposed for 4×4, 8×8, 16×16 and 32×32 angular prediction modes. In the proposed FPGA implementation, one intra angular prediction equation is implemented using one DSP block in FPGA. The proposed FPGA implementation, in the worst case, can process 55 Full HD (1920×1080) video frames per second. It has up to 34.66% less energy consumption than the original FPGA implementation of HEVC intra prediction. Therefore, it can be used in portable consumer electronics products that require a real-time HEVC encoder.","2158-4001","978-1-5386-3025-9978-1-5386-3026","10.1109/ICCE.2018.8326332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326332","HEVC;Intra Prediction;Hardware Implementation;FPGA","Mathematical model;Field programmable gate arrays;Hardware;Adders;Prediction algorithms;Energy consumption;High efficiency video coding","computational complexity;field programmable gate arrays;prediction theory;video coding","High Efficiency Video Coding standard;HEVC intraprediction;FPGA implementation;intraprediction algorithm;computational complexity;angular prediction modes;intraangular prediction equation","","3","16","","","","","IEEE","IEEE Conferences"
"FPGA-Based Real-Time Super-Resolution System for Ultra High Definition Videos","Z. He; H. Huang; M. Jiang; Y. Bai; G. Luo","NA; NA; NA; NA; NA","2018 IEEE 26th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)","","2018","","","181","188","The market benefits from a barrage of Ultra High Definition (Ultra-HD) displays, yet most extant cameras are barely equipped with Full-HD video capturing. In order to upgrade existing videos without extra storage costs, we propose an FPGA-based super-resolution system that enables real-time Ultra-HD upscaling in high quality. Our super-resolution system crops each frame into blocks, measures their total variation values, and dispatches them accordingly to a neural network or an interpolation module for upscaling. This approach balances the FPGA resource utilization, the attainable frame rate, and the image quality. Evaluations demonstrate that the proposed system achieves superior performance in both throughput and reconstruction quality, comparing to current approaches.","2576-2621","978-1-5386-5522-1978-1-5386-5523","10.1109/FCCM.2018.00036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457651","Field-Programmable Gate Arrays;Ultra High Definition;Super-Resolution;Real-time","Image resolution;Neural networks;TV;Interpolation;Real-time systems;Videos;Field programmable gate arrays","cameras;field programmable gate arrays;high definition video;image enhancement;image reconstruction;image resolution;interpolation;video signal processing","FPGA-based real-time super-resolution system;FPGA resource utilization;cameras;Ultra-HD upscaling;ultra high definition videos;ultra high definition displays;interpolation module;image quality;reconstruction quality;full-HD video capturing","","","47","","","","","IEEE","IEEE Conferences"
"Full-HD Accelerated and Embedded Feature Detection Video System with 63fps using ORB for FREAK","L. Kalms; H. Ibrahim; D. Göhringer","Technische Universitát Dresden, Dresden, Germany; German University in Cairo (GUC), Cairo, Egypt; Technische Universitát Dresden, Dresden, Germany","2018 International Conference on ReConFigurable Computing and FPGAs (ReConFig)","","2018","","","1","6","Detecting features using pattern recognition algorithms is a fast method to recognize objects without needing large image databases. Feature detection can be used in e.g. machine learning or Simultaneous Localization and Mapping (SLAM) algorithms. For several application areas, real-time requirements and power constraints are important. FPGAs are predestined for these requirements, due to the possibility of clock-accurate computations. This work proposes a hardware accelerator of the Oriented FAST and Rotated BRIEF (ORB) feature detector implemented as a pipelined design on an FPGA SoC. The accelerator is integrated into an HDMI input/output video processing system. The final system runs with a frequency of 148.5 MHz and processes a 1080p video stream with 63 frames per second (fps). Furthermore, we propose to replace the Binary Robust Independent Elementary Features (BRIEF) with the Fast Retina Keypoint (FREAK) descriptor to improve the performance and repeatability of the algorithm.","2640-0472;2325-6532","978-1-7281-1968-7978-1-7281-1969","10.1109/RECONFIG.2018.8641706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8641706","FPGA;Feature Detection;Image Processing;Real-Time;Video Processing System","Detectors;Hardware;Feature detection;Feature extraction;Streaming media;Signal processing algorithms;Image color analysis","feature extraction;field programmable gate arrays;image matching;object detection;object recognition;pipeline processing;SLAM (robots);system-on-chip;video signal processing","power constraints;clock-accurate computations;Simultaneous Localization and Mapping algorithms;real-time requirements;application areas;machine learning;pattern recognition algorithms;embedded feature detection video system;HD accelerated;FREAK;Fast Retina Keypoint descriptor;Binary Robust Independent Elementary Features;HDMI input/output video processing system;ORB;Rotated BRIEF;Oriented FAST;hardware accelerator;frequency 148.5 MHz","","","17","","","","","IEEE","IEEE Conferences"
"Design of a Gabor Filter HW Accelerator for Applications in Medical Imaging","G. D. Licciardo; C. Cappetta; L. Di Benedetto","Department of Industrial Engineering, University of Salerno, Fisciano, Italy; Department of Industrial Engineering, University of Salerno, Fisciano, Italy; Department of Industrial Engineering, University of Salerno, Fisciano, Italy","IEEE Transactions on Components, Packaging and Manufacturing Technology","","2018","8","7","1187","1194","The Gabor filter (GF) has been proved to show good spatial frequency and position selectivity, which makes it a very suitable solution for visual search, object recognition, and, in general, multimedia processing applications. GFs prove useful also in the processing of medical imaging to improve part of the several filtering operations for their enhancement, denoising, and mitigation of artifact issues. However, the good performances of GFs are compensated by a hardware complexity that traduces in a large amount of mapped physical resources. This paper presents three different designs of a GF, showing different tradeoffs between accuracy, area, power, and timing. From the comparative study, it is possible to highlight the strength points of each one and choose the best design. The designs have been targeted to a Xilinx field-programmable gate array (FPGA) platform and synthesized to 90-nm CMOS standard cells. FPGA implementations achieve a maximum operating frequency among the different designs of 179 MHz, while 350 MHz is obtained from CMOS synthesis. Therefore, 86 and 168 full-HD (1920 × 1080) f/s could be processed, with FPGA and std_cell implementations, respectively. In order to meet space constraints, several considerations are proposed to achieve an optimization in terms of power consumption, while still ensuring real-time performances.","2156-3950;2156-3985","","10.1109/TCPMT.2018.2818947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8338076","Accelerators;field-programmable gate array (FPGA);Gabor filters (GFs);hardware (HW);visual search (VS)","Biomedical imaging;Field programmable gate arrays;Kernel;Feature extraction;Image edge detection;Gabor filters;Visualization","field programmable gate arrays;Gabor filters;image denoising;image enhancement;medical image processing","Gabor filter HW accelerator;medical imaging;GF;FPGA;Xilinx field-programmable gate array;power consumption","","","37","","","","","IEEE","IEEE Journals & Magazines"
"Hardware Architecture for Fast General Object Detection using Aggregated Channel Features","K. Mitsunari; J. Yu; M. Hashimoto","Graduate School of Information Science and Technology, Osaka University; Graduate School of Information Science and Technology, Osaka University; Graduate School of Information Science and Technology, Osaka University","2018 IEEE Asian Solid-State Circuits Conference (A-SSCC)","","2018","","","55","58","For embedded system applications, high detection accuracy and fast detection must be achieved within a limited power budget. This paper proposes an embedded system-oriented hardware accelerator for object detection with aggregated channel features (ACF). The proposed accelerator consists of hardware architectures dedicated for HOG features, quantization, and boosted decision trees, and they contribute to 2006X speed-up and 601X memory reduction. Our FPGA implementation result shows that the proposed accelerator can detect pedestrians at 170 fps for Full HD images, and 6-class traffic objects at 78 fps for Full HD images.","","978-1-5386-6413-1978-1-5386-6414","10.1109/ASSCC.2018.8579337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8579337","","Hardware;Feature extraction;Object detection;Computer architecture;Decision trees;Field programmable gate arrays;Quantization (signal)","decision trees;object detection","general object detection;quantization;boosted decision trees;FPGA;6-class traffic objects;HOG features;embedded system-oriented hardware accelerator;embedded system applications;aggregated channel features;hardware architecture","","","10","","","","","IEEE","IEEE Conferences"
"A Reconfigurable Fractional Interpolation Hardware for VVC Motion Compensation","H. Azgin; A. C. Mert; E. Kalali; I. Hamzaoglu","NA; NA; NA; NA","2018 21st Euromicro Conference on Digital System Design (DSD)","","2018","","","99","103","Fractional interpolation is one of the most computationally complex parts of video compression standards. Fractional interpolation in Versatile Video Coding (VVC) standard has much higher computational complexity than fractional interpolation in previous video compression standards. In this paper, a reconfigurable VVC fractional interpolation hardware for motion compensation is designed and implemented using Verilog HDL. The proposed hardware is the first VVC fractional interpolation hardware for motion compensation in the literature. It interpolates necessary fractional pixels for 1/16 pixel accuracy for all prediction unit sizes. The proposed VVC fractional interpolation hardware, in the worst case, can process 66 quad full HD (3840×2160) frames per second. It has up to 77% less power consumption than baseline VVC fractional interpolation hardware.","","978-1-5386-7377-5978-1-5386-7378","10.1109/DSD.2018.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8491801","VVC;motion compensation;fractional interpolation;hardware implementation;FPGA","Hardware;Interpolation;Finite impulse response filters;Field programmable gate arrays;Motion compensation;Hardware design languages;Clocks","computational complexity;data compression;hardware description languages;interpolation;motion compensation;video coding","computational complexity;video compression standards;fractional pixels;Verilog HDL;Versatile Video Coding standard;computationally complex parts;VVC motion compensation;reconfigurable fractional interpolation hardware;baseline VVC fractional interpolation hardware;reconfigurable VVC fractional interpolation hardware","","","17","","","","","IEEE","IEEE Conferences"
"A Low Power Versatile Video Coding (VVC) Fractional Interpolation Hardware","A. CanMert; E. Kalali; I. Hamzaoglu","Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey","2018 Conference on Design and Architectures for Signal and Image Processing (DASIP)","","2018","","","43","47","Fractional interpolation in Versatile Video Coding (VVC) standard has much higher computational complexity than fractional interpolation in previous video compression standards. In this paper, a low power VVC fractional interpolation hardware is designed and implemented using Verilog HDL. The proposed hardware is the first VVC fractional interpolation hardware in the literature. It interpolates necessary fractional pixels for 1/16 pixel accuracy for all prediction unit sizes. The proposed VVC fractional interpolation hardware, in the worst case, can process 40 full HD (1920×1080) frames per second. It has up to 17% less power consumption than original VVC fractional interpolation hardware.","","978-1-5386-8237-1978-1-5386-8238","10.1109/DASIP.2018.8597040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8597040","VVC;Fractional Interpolation;Hardware Implementation;FPGA;Low Power","Finite impulse response filters;Interpolation;Hardware;Micromechanical devices;Mathematical model;Adders;Clocks","computational complexity;hardware description languages;image resolution;interpolation;video coding","prediction unit sizes;Verilog HDL;low power VVC fractional interpolation hardware;computational complexity;VVC standard;low power versatile video coding fractional interpolation hardware;fractional pixels;versatile video coding standard","","","16","","","","","IEEE","IEEE Conferences"
"Design and Implementation of 2D IDCT/IDST-Specific Accelerator on Heterogeneous Multicore Architecture","M. A. Pourabed; S. Nouri; J. Nurmi","Laboratory of Electronics and Communications Engineering, Tampere University of Technology P.O.Box 553, Tampere, FI-33101, Finland; Laboratory of Electronics and Communications Engineering, Tampere University of Technology P.O.Box 553, Tampere, FI-33101, Finland; Laboratory of Electronics and Communications Engineering, Tampere University of Technology P.O.Box 553, Tampere, FI-33101, Finland","2018 IEEE Nordic Circuits and Systems Conference (NORCAS): NORCHIP and International Symposium of System-on-Chip (SoC)","","2018","","","1","6","The paper talks about how to implement different sizes of Inverse Discrete Cosine Transform (IDCT) as well as Inverse Discrete Sine transform (IDST) that are dedicated on High Efficiency Video Coding (HEVC) standard through employing Coarse-Grained Reconfigurable Arrays (CGRAs) as a template-based accelerators on Heterogeneous Accelerator-Rich Platform (HARP). The proposal designs multi-purpose IDCT/IDST-based accelerators in a manner that the final architecture is made up of 4-point IDST and 4/8-point IDCT. The designing of the accelerators is done by creating template-based CGRA devices at various dimensions after which they are arranged in a sequential manner over a structure that is Network-on-Chip (NoC) based accompanied by a number of RISC cores. The research records the IDCT/IDST-specific accelerator performance, the entire platform's performance, as well as the traffic of the NoC with regard to the total number of clock cycles made as well as several other high-level metrics of performance. The experiments that were conducted found that 4-point IDCT and 4-point IDST can be totally implemented in 56 clock cycles. For 8-point IDCT, the clock cycles required are 64. The total power dissipation, as well as energy consumption centred on information on routing and post placement, are all equal to 4.03 mW and 1.76 μJ for 4-point IDCT/IDST and 3.06 μJ for 8-point IDCT, respectively. Furthermore, the use of 256 instantiated Processing Elements (PEs) at an operating frequency of 200.0 MHz results to a 51.2 Giga Operations Per Second (GOPS) performance and 0.012 GOPS/mW architectural constant for the HARP model on the 28 nm Altera Stratix-V chip. The architecture under the proposal is capable of fully sustaining a format of Full HD 1080P at 30 fps on FPGA.","","978-1-5386-7656-1978-1-5386-7657","10.1109/NORCHIP.2018.8573492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573492","IDCT;IDST;HEVC;HARP;CGRA;Multicore;NoC;RISC;FPGA","Reduced instruction set computing;Computer architecture;Context;Transforms;High efficiency video coding;Standards","discrete cosine transforms;field programmable gate arrays;inverse transforms;microprocessor chips;multiprocessing systems;network-on-chip;reduced instruction set computing;video coding","4-point IDCT/IDST;heterogeneous multicore architecture;template-based accelerators;Heterogeneous Accelerator-Rich Platform;multipurpose IDCT/IDST-based accelerators;inverse discrete cosine transform;inverse discrete sine transform;high efficiency video coding standard;coarse-grained reconfigurable arrays;Network-on-Chip","","","21","","","","","IEEE","IEEE Conferences"
"Design Criteria for Real-time Processing of HW Gabor Filters in Visual Search","G. D. Licciardo; C. Cappetta; L. Di Benedetto","University of Salerno, Dept. of Industrial Engineering (D.I.In.), Fisciano,Italy; University of Salerno, Dept. of Industrial Engineering (D.I.In.), Fisciano,Italy; University of Salerno, Dept. of Industrial Engineering (D.I.In.), Fisciano,Italy","2018 IEEE International Symposium on Circuits and Systems (ISCAS)","","2018","","","1","5","Gabor filters gained a great importance in multimedia processing and visual search applications, thanks to the good spatial frequency and position selectivity, despite of their heavy computational complexity. Further, the large number of parameters to be imposed sets a number of trade-offs between accuracy and complexity making the use of Gabor filters very challenging. In this work, a number of criteria are exploited for a careful choice of the parameters, in order to allow implementing accurate two-dimensional filters, with a computational complexity that can be adapted to target platforms with different capabilities. In order to show this, three hardware designs of a Gabor filter-based edge detection system are derived, implementing two and four orientations, all capable of real-time processing with different Area-Delay-Power performances and accuracies. The derived designs have been implemented on a FPGA-based ASIC prototyping system and synthesized in 90nm CMOS std_cells, returning a maximum operating frequency of 179 MHz and 350 MHz, respectively. Therefore, the proposed filters achieve state-of-the-art performances with the best throughput of 86 and 168 Full-HD (1920×1080 pixels) frames-per-second, for FPGA and std_cell implementations, respectively.","2379-447X","978-1-5386-4881-0978-1-5386-4882","10.1109/ISCAS.2018.8351730","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8351730","Gabor filters;Visual Search;Edge detection;Field Programmable Gate Arrays","Gabor filters;Image edge detection;Kernel;Computational complexity;Field programmable gate arrays;Real-time systems;Visualization","application specific integrated circuits;CMOS logic circuits;edge detection;field programmable gate arrays;Gabor filters;image filtering;integrated circuit design","visual search applications;position selectivity;FPGA-based ASIC prototyping system;spatial frequency;computational complexity;2D filters;area-delay-power performances;edge detection system;HW Gabor filters;CMOS std_cells;multimedia processing;size 90.0 nm;frequency 350.0 MHz;frequency 179 MHz","","","21","","","","","IEEE","IEEE Conferences"
"High-Speed CMOS Color Stereo Camera with Low Complexity VLSI Implementation for Real-Time 3D Vision Applications","J. Lee; M. Kim; H. Kwon; B. You","Center of Human-centered Interaction for Coexistence (CHIC), Seoul, 02792, Korea; Center of Human-centered Interaction for Coexistence (CHIC), Seoul, 02792, Korea; Center of Human-centered Interaction for Coexistence (CHIC), Seoul, 02792, Korea; Center of Human-centered Interaction for Coexistence (CHIC), Seoul, 02792, Korea","2018 15th International Conference on Ubiquitous Robots (UR)","","2018","","","506","510","The paper presents alow complexity hardware architecture of CMOS color stereo camera for real-time 3D vision applications. To minimize the hardware complexity, two key ideas are applied. Firstly, a hardware architecture sharing line-by-line overlapped convolution kernels is proposed to reduce the number of arithmetic operations in demosaicing of bayer RGB images without image quality degradation. Secondly, an adaptive sync compensation module is proposed to synchronize master/slave image sensors, and display devices by compensating the sync signals period of slave image sensor and display devices in real-time, after monitoring varying periods of the master sync signals. In consequence, external memories such as SDRAM, that can be a considerable overhead in stereo camera implementation, is completely removed. The proposed hardware architecture is verified that the number of logic elements and registers of Intel Max10 FPGA (10M16DCU324I7G) is reduced by 69% and 76% respectively comparing to demo-saicing hardware without sharing and external memory based architecture. Also, the developed stereo camera can capture full-HD stereo images at 60 FPS and/or<tex>$\pmb{1920\times 1200\mathrm{p}}$</tex>stereo images at 54 FPS. Moreover, it is more preferable in real-time 3D vision applications.","","978-1-5386-6334-9978-1-5386-6333-2978-1-5386-6335","10.1109/URAI.2018.8441809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8441809","","Synchronization;Image sensors;Hardware;Cameras;Complexity theory;Computer architecture;Convolution","","","","","16","","","","","IEEE","IEEE Conferences"
"Design and Implementation of Multi-Purpose DCT/DST-Specific Accelerator on Heterogeneous Multicore Architecture","S. Nouri; R. Ghaznavi-Youvalari; J. Nurmi","Laboratory of Electronics and Communications Engineering, Tampere University of Technology, Finland; Nokia Technologies, Finland; Laboratory of Electronics and Communications Engineering, Tampere University of Technology, Finland","2018 IEEE Nordic Circuits and Systems Conference (NORCAS): NORCHIP and International Symposium of System-on-Chip (SoC)","","2018","","","1","10","This paper presents the implementation of various sizes of Discrete Cosine transform (DCT) and Discrete Sine Transform (DST) dedicated for High Efficiency Video Coding (HEVC) standard by using template-based Coarse-Grained Reconfigurable Arrays (CGRAs) as accelerators on Heterogeneous Accelerator-Rich Platform (HARP). The proposal makes multipurpose DCT/DST specific accelerators in such a way that final architecture consists of 4/8/16/32-point DCT and 4-point DST. The accelerators are primarily designed by crafting template-based CGRA devices at different dimensions and then arranging them on a Network-on-Chip platform along with a few RISC cores. In this research work, the performance of each DCT/DST-specific accelerator, the collective performance of the whole platform and the NoC traffic are recorded in terms of the number of clock cycles and several high-level performance metrics. Conducted experiments show that 4-point DCT and 4-point DST can be implemented completely in 54 and 56 clock cycles, respectively, while for 8/16/32-point DCT, 67, 179 and 354 clock cycles are required, respectively. The achieved total power dissipation and energy consumption based on post placement and routing information are equal to 4.1 W and $10.87~\mu {\mathrm {J}}$, respectively with 256 instantiated Processing Elements (PEs) at 200.0 MHz operating frequency. It resulted to a performance of 51.2 Giga Operations Per Second (GOPS) and 12 MOPS/mW as an architectural constant for the HARP template on 28 nm Altera Stratix-V chip. The proposed architecture is able to sustain Full HD 1080p format at 30 fps on FPGA.","","978-1-5386-7656-1978-1-5386-7657","10.1109/NORCHIP.2018.8573457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573457","Reconfigurable;CGRA;Network-on-Chip;Heterogeneous;Accelerator;Multicore;DCT;DST;HEVC","Discrete cosine transforms;Reduced instruction set computing;Standards;Computer architecture;Video coding;Acceleration","discrete cosine transforms;field programmable gate arrays;microprocessor chips;multiprocessing systems;network-on-chip;reconfigurable architectures;reduced instruction set computing;video coding","4/8/16/32-point DCT;4-point DST;high-level performance metrics;4-point DCT;multipurpose DCT-DST-specific accelerator;heterogeneous multicore architecture;discrete sine transform;high efficiency video coding standard;multipurpose DCT-DST specific accelerators;heterogeneous accelerator-rich platform","","","11","","","","","IEEE","IEEE Conferences"
